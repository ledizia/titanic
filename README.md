# Titanic Survival Prediction API ğŸš¢

A FastAPI-based machine learning API for predicting survival on the Titanic dataset. This project provides a complete ML pipeline with preprocessing, model serving and testing.

## ğŸš€ Features

- **FastAPI REST API** with automatic documentation
- **Machine Learning Model** for survival prediction
- **Data Preprocessing Pipeline** with feature engineering
- **Testing** (unit, integration, end-to-end)
- **Prometheus Metrics** for monitoring
- **Docker Support** for containerization

## ğŸ“ Project Structure

```
titanic/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â”œâ”€â”€ preprocess_data.py        # Data preprocessing pipeline
â”‚   â””â”€â”€ models/                   # Trained model files
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ conftest.py               # Shared test fixtures
â”‚   â”œâ”€â”€ unit/                     # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_main.py          # API endpoint tests
â”‚   â”‚   â”œâ”€â”€ test_models.py        # Pydantic model tests
â”‚   â”‚   â”œâ”€â”€ test_preprocess_data.py # Preprocessing tests
â”‚   â”‚   â””â”€â”€ test_helpers.py       # Utility function tests
â”‚   â””â”€â”€ integration/              # Integration tests
â”‚       â”œâ”€â”€ test_api_workflows.py # API workflow tests
â”‚       â”œâ”€â”€ test_end_to_end.py    # End-to-end tests
â”‚       â””â”€â”€ test_preprocessing_pipeline.py # Pipeline tests
â”œâ”€â”€ data/                         # Dataset files
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ pytest.ini                   # Pytest configuration
â””â”€â”€ .gitignore                   # Git ignore rules
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.9
- pip or conda

### Setup

1. **Clone the repository:**

2. **Create and activate virtual environment:**
   ```bash
   python3.9 -m venv titanic
   source titanic/bin/activate  # On Windows: titanic\Scripts\activate
   ```
3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ³ Docker

### Building the Image

```bash
docker build -t titanic-api .
```

### Running with Docker

```bash
docker run -p 8000:8000 titanic-api
```

### Making Predictions

**Example API call:**
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "Pclass": 3,
       "Name": "Braund, Mr. Owen Harris",
       "Sex": "male",
       "Age": 22.0,
       "SibSp": 1,
       "Parch": 0,
       "Ticket": "A/5 21171",
       "Fare": 7.25,
       "Cabin": "",
       "Embarked": "S"
     }'
```

**Response:**
```json
{
  "prediction": 0,
  "prediction_label": "Not Survived",
  "probabilities": [0.7, 0.3],
  "message": "Prediction completed successfully."
}
```

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/           # Unit tests only
pytest tests/integration/    # Integration tests only
```

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | API health check |
| `/predict` | POST | Make survival prediction |
| `/load` | POST | Load new model |
| `/history` | GET | Get prediction history |
| `/metrics` | GET | Prometheus metrics |
| `/docs` | GET | API documentation |

## ğŸ“ˆ Monitoring

### Prometheus Metrics

The API exposes comprehensive Prometheus metrics for monitoring and alerting:

- **Request Metrics**: Total requests
- **Error Metrics**: Categorized errors with labels for error type and status code
- **State Metrics**: Prediction history count

#### Key Metrics:
- `titanic_prediction_requests_total` - Total prediction requests
- `titanic_prediction_errors_total` - Errors with labels for categorization (`error_type`, `status_code`)

#### Error Categories:
- `validation_error` - Data validation errors
- `internal_error` - Unexpected server errors
- `model_not_loaded` - Model not available
- `model_not_found` - Model file not found
- `model_load_error` - Model loading failures

## ğŸ“ License

This project is licensed under the MIT License.